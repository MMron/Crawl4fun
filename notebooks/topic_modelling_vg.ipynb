{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import pickle\n",
    "import urllib\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import os, re, operator, warnings\n",
    "warnings.filterwarnings('ignore')  # Let's not pay heed to them right now\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_cleaning(df):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df = (df.assign(url_new = lambda x : x.url.str.split(\":\",expand=True)[1]) #remove http and https \n",
    "            .sort_values(by='pub_date', ascending=False, na_position='last')\n",
    "            .drop_duplicates(subset='url_new', keep='first'))\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vg_plus_cleaning(df):\n",
    "    \"\"\"\n",
    "    clean vgs + related articles (subscription related articles)\n",
    "    \"\"\"\n",
    "    df = df.drop(df.index[df.text_len<30])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vg_file(file):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    #df = pd.read_json(json.dumps(pickle.load( open( data_folder+name, \"rb\" ) )))\n",
    "    \n",
    "    #data = pd.DataFrame()\n",
    "    #pd.DataFrame.from_dict(pickle.load(open(\"../spiders/data/vg/20.03.01_18:56:02.pickle\",\"rb\")))\n",
    "    df = (pd.DataFrame.from_dict(pickle.load(open(file,'rb')))\n",
    "            .replace('None', np.nan)\n",
    "            .assign(text_len= lambda x: x.text.str.len())\n",
    "            .assign(pub_date=lambda x: pd.to_datetime(x['pub_date']))\n",
    "            .dropna(axis=0,subset=['text'])\n",
    "            .sort_values(by='pub_date',na_position='last')\n",
    "            .pipe(url_cleaning)\n",
    "            .pipe(vg_plus_cleaning)#test[test.x > 0].index\n",
    "         )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../spiders/data/vg/\"\n",
    "name1 = \"20.03.01_21:00:01.pickle\"\n",
    "data = read_vg_file(folder+name1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "orginalt: 34931 etter: 34468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vg_data(folder):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    files = os.listdir(folder)\n",
    "    df = pd.DataFrame(columns = ['url','text','title','pub_date'])\n",
    "    for file in files:\n",
    "        #read, sanity check, sort on date, remove duplicates\n",
    "        # merge with exicting, sort on date, remove duplicates \n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"nb_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name = '20.01.23 23:19:58.pickle'\n",
    "name = \"20.03.01_18:56:02.pickle\"\n",
    "data_folder = \"../spiders/data/vg/\"\n",
    "with open(data_folder+name, 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>text_len</th>\n",
       "      <th>url_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>Det viser et dokument datert 27. mai 2016, som...</td>\n",
       "      <td>Sykkelpresidenten ga seg selv kredittkort-gara...</td>\n",
       "      <td>https://www.vg.no/sport/sykkel/i/J1Rwa6/sykkel...</td>\n",
       "      <td>2018-03-08 09:40:54</td>\n",
       "      <td>3958.0</td>\n",
       "      <td>//www.vg.no/sport/sykkel/i/J1Rwa6/sykkelpresid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10533</th>\n",
       "      <td>Det sier høyprofilerte Rangappa i dette interv...</td>\n",
       "      <td>Tidligere FBI-agent om Trump: «Hvorfor lyve hv...</td>\n",
       "      <td>https://www.vg.no/nyheter/utenriks/i/21lrVr/ti...</td>\n",
       "      <td>2018-05-12 15:33:55</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>//www.vg.no/nyheter/utenriks/i/21lrVr/tidliger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16994</th>\n",
       "      <td>– Forutsigbarhet. Norsk fotball trenger foruts...</td>\n",
       "      <td>Snart får du vite når seriestarten blir - i 20...</td>\n",
       "      <td>https://www.vg.no/sport/fotball/i/vmzKdm/snart...</td>\n",
       "      <td>2018-03-10 18:37:53</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>//www.vg.no/sport/fotball/i/vmzKdm/snart-faar-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "34999  Det viser et dokument datert 27. mai 2016, som...   \n",
       "10533  Det sier høyprofilerte Rangappa i dette interv...   \n",
       "16994  – Forutsigbarhet. Norsk fotball trenger foruts...   \n",
       "\n",
       "                                                   title  \\\n",
       "34999  Sykkelpresidenten ga seg selv kredittkort-gara...   \n",
       "10533  Tidligere FBI-agent om Trump: «Hvorfor lyve hv...   \n",
       "16994  Snart får du vite når seriestarten blir - i 20...   \n",
       "\n",
       "                                                     url            pub_date  \\\n",
       "34999  https://www.vg.no/sport/sykkel/i/J1Rwa6/sykkel... 2018-03-08 09:40:54   \n",
       "10533  https://www.vg.no/nyheter/utenriks/i/21lrVr/ti... 2018-05-12 15:33:55   \n",
       "16994  https://www.vg.no/sport/fotball/i/vmzKdm/snart... 2018-03-10 18:37:53   \n",
       "\n",
       "       text_len                                            url_new  \n",
       "34999    3958.0  //www.vg.no/sport/sykkel/i/J1Rwa6/sykkelpresid...  \n",
       "10533    4444.0  //www.vg.no/nyheter/utenriks/i/21lrVr/tidliger...  \n",
       "16994    1308.0  //www.vg.no/sport/fotball/i/vmzKdm/snart-faar-...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stop_ord = \"https://gist.githubusercontent.com/kmelve/8869818/raw/407980a1d89a385283d738e1545ab1b2014e87be/stoppord_no\"\n",
    "response = requests.get(url_stop_ord,)\n",
    "my_stop_words = response.content.decode(\"utf-8\") .split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stopword in my_stop_words:\n",
    "    lexeme = nlp.vocab[stopword]\n",
    "    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        (Ullevål, sykehus, skjerpet, søndag, sine, kar...\n",
       "35033    (Folkehelseinstituttet, opplyser, at, tolv, av...\n",
       "35011    (Folkehelseinstituttet, opplyser, at, tolv, av...\n",
       "35012    ( , Myndighetene, i, Seoul, har, anmeldt, Lee,...\n",
       "35009    (Nå, krever, Norges, største, parti, at, det, ...\n",
       "30       (I, fjor, fortalte, politifolk, i, Kripos, til...\n",
       "13       (En, konsekvens, av, Det, hører, med, i, dette...\n",
       "26       (I, går, kveld, Andersen, tiltrådte, som, stat...\n",
       "29       (–, Vi, har, sett, dette, tydelig, de, siste, ...\n",
       "28       (Du, vinker, meg, til, side, i, korridoren, .,...\n",
       "11       ( , Wold, bor, og, jobber, i, Istanbul, ,, men...\n",
       "6        (17, personer, har, fått, påvist, coronaviruse...\n",
       "14       (Det, kommer, frem, i, en, oppdatering, fra, O...\n",
       "34       (Det, kommer, frem, i, en, oppdatering, fra, O...\n",
       "51       (Det, kommer, frem, i, en, oppdatering, fra, O...\n",
       "23       (Marcello, Longhi, er, prest, i, en, av, mange...\n",
       "3        (–, Alle, de, 15, har, relasjon, til, utbredel...\n",
       "2        (Biden, gjorde, et, kjempebyks, fremover, unde...\n",
       "24       (Biden, gjorde, et, kjempebyks, fremover, unde...\n",
       "27       (–, Denne, kampanjen, tar, av, ,, ropte, den, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][:20].astype('unicode').apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Ullevål sykehus skjerpet søndag sine karantene...\n",
       "35033    Folkehelseinstituttet opplyser at tolv av tilf...\n",
       "35011    Folkehelseinstituttet opplyser at tolv av tilf...\n",
       "35012     Myndighetene i Seoul har anmeldt Lee Man-hee,...\n",
       "35009    Nå krever Norges største parti at det nedsette...\n",
       "                               ...                        \n",
       "5384     Lykkelig over at katten ikke ser ut til å ha n...\n",
       "925      Jo, det er Tom Hanks. Juryen har talt.Det var ...\n",
       "30096    Ifølge TV 2 har Nygaard nylig mottatt et brev ...\n",
       "4562     Norske TV-seere har kunnet følge Dawson, spilt...\n",
       "5366     Hun merket ikke at en av husets katter hadde l...\n",
       "Name: text, Length: 34468, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.6 s, sys: 7.14 s, total: 1min 4s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12516    (Vertslandet, Norge, oppjusterer, også, antall...\n",
       "32670    (Det, er, solgt, cirka, 22.000, billetter, til...\n",
       "4385     (Det, statlige, nyhetsbyrået, SANA, skriver, a...\n",
       "20452    (–, Jeg, synes, det, er, gøy, å, prøve, litt, ...\n",
       "9073     (Belgia, hadde, lenge, problemer, med, å, bryt...\n",
       "                               ...                        \n",
       "10623    (Kilder, Ifølge, CNN, hevder, Cohen, å, ha, væ...\n",
       "19644    (–, Vi, kunne, lent, oss, tilbake, og, gått, p...\n",
       "27711    (–, Jeg, er, totalt, forandret, siden, sist, ....\n",
       "16828    (Til, mandag, er, det, skolestart, over, hele,...\n",
       "362      (I, en, Twitter, -, melding, natt, til, tirsda...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data['text'].sample(1000).apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processes_text'] = pd.Series(np.nan, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "fold 10\n",
      "fold 11\n",
      "fold 12\n",
      "fold 13\n",
      "fold 14\n",
      "fold 15\n",
      "fold 16\n",
      "fold 17\n",
      "fold 18\n",
      "fold 19\n",
      "fold 20\n",
      "fold 21\n",
      "fold 22\n",
      "fold 23\n",
      "fold 24\n",
      "fold 25\n",
      "fold 26\n",
      "fold 27\n",
      "fold 28\n",
      "fold 29\n",
      "CPU times: user 32min 37s, sys: 6min 56s, total: 39min 34s\n",
      "Wall time: 40min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i, chunk in enumerate(np.array_split(data.index.values, 30)):\n",
    "    print(f'fold {i}')\n",
    "    data['processes_text'].loc[chunk] = data['text'].loc[chunk].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1586464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.516672"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.memory_usage(index=True).sum()/10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores=4):\n",
    "    \"\"\"\n",
    "    https://towardsdatascience.com/make-your-own-super-pandas-using-multiproc-1c04f41944a1\n",
    "    \"\"\"\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lass = parallelize_dataframe(df.text,nlp)#train = parallelize_dataframe(train_df, add_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add some words to the stop word list\n",
    "texts, article = [], []\n",
    "for pd_article in data.processes_text:\n",
    "    for w in pd_article: \n",
    "        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n",
    "            article.append(w.lemma_)\n",
    "    texts.append(article)\n",
    "    article = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(texts)\n",
    "texts = [bigram[line] for line in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.292*\"VG\" + 0.253*\" \" + 0.158*\"møte\" + 0.155*\"parti\" + 0.154*\"fortelle\" + 0.124*\"skje\" + 0.123*\"vite\" + 0.107*\"barn\" + 0.106*\"Trump\" + 0.105*\"snakke\"'),\n",
       " (1,\n",
       "  '0.393*\"parti\" + -0.332*\"spiller\" + -0.279*\"spille\" + 0.268*\"KrF\" + -0.190*\"Solskjær\" + 0.183*\" \" + -0.174*\"klubbe\" + 0.171*\"Frp\" + -0.154*\"sesong\" + -0.134*\"kamp\"'),\n",
       " (2,\n",
       "  '-0.559*\"Trump\" + 0.372*\"parti\" + 0.245*\"KrF\" + 0.196*\"spiller\" + 0.172*\"spille\" + -0.148*\"barn\" + 0.145*\"Frp\" + -0.135*\"president\" + 0.118*\"Solskjær\" + -0.109*\" \"'),\n",
       " (3,\n",
       "  '0.712*\" \" + -0.450*\"Trump\" + -0.230*\"parti\" + 0.151*\"barn\" + 0.127*\"VG\" + -0.113*\"KrF\" + -0.111*\"møte\" + -0.107*\"president\" + 0.091*\"skole\" + -0.074*\"valg\"'),\n",
       " (4,\n",
       "  '-0.571*\" \" + 0.344*\"barn\" + -0.326*\"Trump\" + 0.297*\"VG\" + 0.229*\"fortelle\" + -0.147*\"spiller\" + -0.117*\"spille\" + -0.103*\"Solskjær\" + 0.099*\"skole\" + -0.098*\"parti\"'),\n",
       " (5,\n",
       "  '0.604*\"VG\" + -0.523*\"barn\" + -0.183*\"skole\" + -0.144*\"  \" + 0.138*\"møte\" + -0.122*\"parti\" + 0.110*\"fortelle\" + -0.107*\"små\" + -0.093*\"forelder\" + -0.073*\"elev\"'),\n",
       " (6,\n",
       "  '-0.455*\"barn\" + -0.294*\"KrF\" + 0.277*\"  \" + -0.248*\"Trump\" + 0.195*\"EU\" + 0.192*\"avtale\" + -0.165*\"møte\" + -0.158*\"Hareide\" + -0.147*\"Ropstad\" + -0.145*\"Solskjær\"'),\n",
       " (7,\n",
       "  '0.467*\"Solskjær\" + 0.267*\"  \" + 0.242*\"United\" + -0.209*\"parti\" + -0.187*\"fortelle\" + 0.176*\"VG\" + -0.172*\"VM\" + 0.164*\"Manchester_United\" + -0.150*\"spille\" + 0.146*\"avtale\"'),\n",
       " (8,\n",
       "  '0.785*\"  \" + 0.255*\"KrF\" + -0.173*\"parti\" + -0.171*\"Solskjær\" + 0.133*\"Hareide\" + -0.120*\"avtale\" + 0.110*\"Ropstad\" + -0.108*\"EU\" + 0.101*\"møte\" + 0.098*\"  _  \"'),\n",
       " (9,\n",
       "  '0.359*\"møte\" + 0.292*\"avtale\" + -0.275*\"parti\" + -0.250*\"  \" + 0.235*\"KrF\" + -0.229*\"Trump\" + 0.211*\"EU\" + -0.192*\"VG\" + -0.178*\"Solskjær\" + -0.173*\"Frp\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsimodel = LsiModel(corpus=corpus, num_topics=20, id2word=dictionary)\n",
    "lsimodel.show_topics(num_topics=10)  # Showing only the top 5 topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*VG + 0.005*  + 0.003*fortelle + 0.003*møte + 0.003*parti + 0.002*skje + 0.002*spille + 0.002*vite + 0.002*spiller + 0.002*Trump + 0.002*legge + 0.002*dag + 0.002*snakke + 0.002*små + 0.002*uke + 0.002*jo + 0.002*følge + 0.002*holde + 0.002*egen + 0.002*svare'),\n",
       " (1,\n",
       "  '0.005*VG + 0.004*barn + 0.004*møte + 0.003*  + 0.003*vite + 0.003*fortelle + 0.003*parti + 0.002*uke + 0.002*Trump + 0.002*skje + 0.002*egen + 0.002*jobbe + 0.002*snakke + 0.002*svare + 0.002*små + 0.002*støtte + 0.002*heller + 0.002*dag + 0.002*jobb + 0.002*jo'),\n",
       " (2,\n",
       "  '0.004*avtale + 0.004*EU + 0.003*  + 0.003*Johnson + 0.003*statsminister + 0.003*Solskjær + 0.003*spiller + 0.003*Storbritannia + 0.002*små + 0.002*skje + 0.002*uke + 0.002*brexit + 0.002*egen + 0.002*spille + 0.002*dag + 0.002*jobb + 0.002*Manchester_United + 0.002*fortelle + 0.002*VG + 0.002*Boris_Johnson'),\n",
       " (3,\n",
       "  '0.005*Trump + 0.004*VG + 0.003*Iran + 0.003*  + 0.003*fortelle + 0.003*barn + 0.002*møte + 0.002*stemme + 0.002*situasjon + 0.002*område + 0.002*uke + 0.002*holde + 0.002*vite + 0.002*avtale + 0.002*støtte + 0.002*Johnson + 0.002*dag + 0.002*små + 0.001*angrep + 0.001*vår'),\n",
       " (4,\n",
       "  '0.005*VG + 0.004*Trump + 0.003*skje + 0.003*spiller + 0.003*fortelle + 0.002*spille + 0.002*  + 0.002*møte + 0.002*dag + 0.002*familie + 0.002*snakke + 0.002*president + 0.002*vite + 0.002*Solskjær + 0.002*fortsette + 0.002*små + 0.002*reise + 0.002*jobbe + 0.001*område + 0.001*Lagerbäck'),\n",
       " (5,\n",
       "  '0.003*liv + 0.003*VG + 0.003*velge + 0.002*spille + 0.002*spiller + 0.002*  + 0.002*Solskjær + 0.002*Haaland + 0.002*fortelle + 0.002*tenke + 0.002*kanskje + 0.002*snakke + 0.001*gire + 0.001*Champions_League + 0.001*parti + 0.001*bør + 0.001*holde + 0.001*dag + 0.001*Giske + 0.001*Liverpool'),\n",
       " (6,\n",
       "  '0.004*møte + 0.003*VG + 0.002*Trump + 0.002*Støre + 0.002*valg + 0.002*ordfører + 0.002*skje + 0.001*klubbe + 0.001*kommune + 0.001*ansette + 0.001*parlament + 0.001*vår + 0.001*Yssen + 0.001*snakke + 0.001*parti + 0.001*lov + 0.001*kommentere + 0.001*president + 0.001*Litauen + 0.001*fortsette'),\n",
       " (7,\n",
       "  '0.006*Trump + 0.003*VG + 0.003*avtale + 0.003*Ukraina + 0.002*vite + 0.002*møte + 0.002*-PRON- + 0.002*etterforskning + 0.002*fortsette + 0.002*samtale + 0.002*amerikansk + 0.002*klubbe + 0.002*president + 0.002*kjent + 0.001*klar + 0.001*bekrefte + 0.001*sommer + 0.001*Biden + 0.001*sanksjon + 0.001*snakke'),\n",
       " (8,\n",
       "  '0.002*møte + 0.002*Frode_Berg + 0.002*Berg + 0.002*EU + 0.002*russisk + 0.002*VG + 0.001*leng + 0.001*avtale + 0.001*  + 0.001*Lavrov + 0.001*nordmann + 0.001*si + 0.001*Litauen + 0.001*skje + 0.001*E_tjeneste + 0.001*små + 0.001*vår + 0.001*kjenne + 0.001*liten + 0.001*Solberg'),\n",
       " (9,\n",
       "  '0.002*EU + 0.002*MDG + 0.001*VG + 0.001*holde + 0.001*spiller + 0.001*Rosenborg + 0.001*stemme + 0.001*Solskjær + 0.001*parti + 0.001*vise + 0.001*melde + 0.001*Russell + 0.001*skotte + 0.001*prognose + 0.001*skje + 0.001*si + 0.001*møte + 0.001*valg + 0.001*frem + 0.001*Manchester_United'),\n",
       " (10,\n",
       "  '0.002*Solskjær + 0.001*spiller + 0.001*Tottenham + 0.001*Manchester_United + 0.001*VG + 0.001*kommune + 0.001*spille + 0.001*slå + 0.001*Old_Trafford + 0.001*Maguire + 0.001*begynne + 0.001*derfor + 0.001*United + 0.001*holde + 0.001*vanskelig + 0.001*Pochettino + 0.001*innlegg + 0.001*vannscooter + 0.001*skrive + 0.001*ordfører'),\n",
       " (11,\n",
       "  '0.004*russer + 0.002*Sondland + 0.002*VG + 0.002*fortelle + 0.001*Maguire + 0.001*spørsmål + 0.001*Trump + 0.001*spille + 0.001*Hansen + 0.001*varsel + 0.001*møte + 0.001*Manchester_United + 0.001*russisk + 0.001*hvit_hus + 0.001*Solskjær + 0.001*egen + 0.001*informasjon + 0.001*nordmann + 0.001*snakke + 0.001*dag'),\n",
       " (12,\n",
       "  '0.003*avtale + 0.003*VG + 0.001*VM + 0.001*medium + 0.001*spille + 0.001*kjenne + 0.001*mulig + 0.001*jo + 0.001*kamp + 0.001*  + 0.001*skje + 0.001*spiller + 0.001*flertall + 0.001*ettersom + 0.001*dag + 0.001*klokke + 0.001*bety + 0.001*følge + 0.001*vinne + 0.001*Farage'),\n",
       " (13,\n",
       "  '0.002*Skottland + 0.002*Tyrkia + 0.001*støtte + 0.001*avtale + 0.001*vår + 0.001*stemme + 0.001*bety + 0.001*barn + 0.001*skje + 0.001*bruke + 0.001*EU + 0.001*dersom + 0.001*VG + 0.001*tyrker + 0.001*Boris_Johnson + 0.001*Syria + 0.001*Frode_Berg + 0.001*stem + 0.001*flertall + 0.001*Sanders'),\n",
       " (14,\n",
       "  '0.002*svare + 0.001*Solskjær + 0.001*spille + 0.001*NATO + 0.001*holde + 0.001*straffe + 0.001*United + 0.001*parti + 0.001*Trump + 0.001*Hellesø + 0.001*Macron + 0.001*lag + 0.001*VG + 0.001*spørsmål + 0.001*samle + 0.001*burde + 0.001*fortsette + 0.001*jo + 0.001*møte + 0.001*Stoltenberg'),\n",
       " (15,\n",
       "  '0.002*tyrkisk + 0.002*angrep + 0.001*mobil + 0.001*YPG + 0.001*Trump + 0.001*kunngjøre + 0.001*Tyrkia + 0.001*syrisk + 0.001*skje + 0.001*side + 0.001*Ras_al + 0.001*grense + 0.001*dag + 0.001*område + 0.001*varsle + 0.001*Erdogan + 0.001*  + 0.001*møte + 0.001*VG + 0.001*region'),\n",
       " (16,\n",
       "  '0.002*Solskjær + 0.002*klubbe + 0.001*Liverpool + 0.001*Tottenham + 0.001*uke + 0.001*Premier_League + 0.001*slå + 0.001*bytte + 0.001*vinne + 0.001*møte + 0.001*fortsette + 0.001*jobbe + 0.001*Solskjærs + 0.001*spiller + 0.001*sparke + 0.001*komme + 0.001*desember + 0.001*Chelsea + 0.001*Manchester_United + 0.001*tape'),\n",
       " (17,\n",
       "  '0.002*Irland + 0.002*Nord_Irland + 0.001*svare + 0.001*Ødegaard + 0.001*avis + 0.001*valgkomite + 0.001*jobb + 0.001*følge + 0.001*velge + 0.001*VG + 0.001*snakke + 0.001*hindre_brexit + 0.001*levestandard + 0.001*akkurat + 0.001*Frode_Berg + 0.001*spiller + 0.001*Hein_Bæra + 0.001*økonomisk + 0.001*melding + 0.001*Fitzgerald'),\n",
       " (18,\n",
       "  '0.003*VG + 0.003*Helge_Ingstad + 0.003*svare + 0.002*skip + 0.002*KNM_Helge + 0.002*Sola_TS + 0.002*bekrefte + 0.002*Fedje_VTS + 0.001*tilgang + 0.001*Hagen + 0.001*sekund + 0.001*feil + 0.001*forstå + 0.001*bord_skip + 0.001*Ingstad + 0.001*spørre_Sola + 0.001*fregatt_knop + 0.001*høre + 0.001*område + 0.001*cirka_halvtime'),\n",
       " (19,\n",
       "  '0.003*EU + 0.002*Irland + 0.001*medlem + 0.001*irsk + 0.001*Frode_Berg + 0.001*møte + 0.001*O_Connell + 0.001*VG + 0.001*brexit + 0.001*brite + 0.001*EOS_utvalg + 0.001*Berg + 0.001*britisk + 0.001*fantastisk + 0.001*Nord_Irland + 0.001*fortsette + 0.001*snakke + 0.001*venstreback + 0.001*Navalnyj + 0.001*støtte')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)\n",
    "hdpmodel.show_topics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6,\n",
       "  '0.010*\"jo\" + 0.009*\"låt\" + 0.006*\"spille\" + 0.006*\"skuespiller\" + 0.005*\"kjenne\" + 0.005*\"hund\" + 0.005*\"musikk\" + 0.005*\"fin\" + 0.005*\"alltid\" + 0.005*\"serie\"'),\n",
       " (11,\n",
       "  '0.024*\"EU\" + 0.018*\"avtale\" + 0.012*\"valg\" + 0.011*\" \" + 0.011*\"parti\" + 0.010*\"politisk\" + 0.009*\"stemme\" + 0.009*\"statsminister\" + 0.007*\"dersom\" + 0.006*\"Storbritannia\"'),\n",
       " (7,\n",
       "  '0.037*\"russisk\" + 0.020*\"Putin\" + 0.014*\"Syria\" + 0.013*\"IS\" + 0.012*\"russer\" + 0.007*\"Moskva\" + 0.006*\"myndighet\" + 0.005*\"sivil\" + 0.005*\"Tyrkia\" + 0.005*\"gruppe\"'),\n",
       " (10,\n",
       "  '0.010*\" \" + 0.009*\"område\" + 0.008*\"fortelle\" + 0.008*\"dag\" + 0.007*\"uke\" + 0.007*\"skade\" + 0.007*\"melde\" + 0.007*\"fly\" + 0.006*\"bile\" + 0.006*\"VG\"'),\n",
       " (9,\n",
       "  '0.037*\"Real_Madrid\" + 0.017*\"Rangers\" + 0.013*\"spansk\" + 0.010*\"Spania\" + 0.010*\"Madrid\" + 0.009*\"Ramos\" + 0.007*\"b\" + 0.006*\"sluttavtale\" + 0.006*\"Zidane\" + 0.005*\"utvisning\"'),\n",
       " (12,\n",
       "  '0.020*\"film\" + 0.012*\"tv\" + 0.008*\" \" + 0.008*\"program\" + 0.007*\"TV\" + 0.007*\"deltager\" + 0.007*\"programleder\" + 0.007*\"kjæreste\" + 0.006*\"Cameron\" + 0.005*\"innspilling\"'),\n",
       " (19,\n",
       "  '0.008*\"øke\" + 0.007*\"små\" + 0.006*\"selskap\" + 0.006*\"høy\" + 0.005*\"penger\" + 0.005*\"økonomisk\" + 0.004*\"åre\" + 0.004*\"gire\" + 0.004*\"selge\" + 0.004*\"størst\"'),\n",
       " (16,\n",
       "  '0.008*\"jo\" + 0.007*\" \" + 0.006*\"synes\" + 0.005*\"heller\" + 0.005*\"legge\" + 0.005*\"egen\" + 0.004*\"velge\" + 0.004*\"vite\" + 0.004*\"tenke\" + 0.004*\"kanskje\"'),\n",
       " (1,\n",
       "  '0.016*\"spille\" + 0.012*\"VM\" + 0.009*\"dommer\" + 0.009*\"vinne\" + 0.008*\"seier\" + 0.007*\"slå\" + 0.006*\"omgang\" + 0.005*\"stå\" + 0.005*\"tape\" + 0.005*\"klare\"'),\n",
       " (2,\n",
       "  '0.013*\"utøver\" + 0.012*\"ol\" + 0.009*\"idrett\" + 0.008*\"IOC\" + 0.005*\"søknad\" + 0.004*\"organisasjon\" + 0.004*\"forbund\" + 0.004*\"doping\" + 0.004*\"NIF\" + 0.004*\"styr\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel = LdaModel(corpus=corpus, num_topics=20, id2word=dictionary)\n",
    "ldamodel.show_topics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_spacy]",
   "language": "python",
   "name": "conda-env-nlp_spacy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
